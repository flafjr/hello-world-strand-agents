{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9a086f",
   "metadata": {},
   "source": [
    "# Advanced Agent Patterns with Strand Agents\n",
    "\n",
    "This notebook explores advanced patterns and techniques for building sophisticated multi-agent systems with Amazon Strand Agents and Ollama.\n",
    "\n",
    "## Topics Covered\n",
    "1. Agent Orchestration Patterns\n",
    "2. Memory and Context Management\n",
    "3. Error Handling and Resilience\n",
    "4. Performance Optimization\n",
    "5. Agent Composition and Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import asyncio\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from agents.ollama_agent import OllamaStrandAgent\n",
    "from agents.specialized_agents import *\n",
    "from tools.custom_tools import *\n",
    "from config.ollama_config import ollama_config\n",
    "\n",
    "print(\"Advanced Agent Patterns - Setup Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b0c21",
   "metadata": {},
   "source": [
    "## 1. Agent Orchestration Patterns\n",
    "\n",
    "Let's implement different patterns for orchestrating multiple agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a558c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrates multiple agents for complex workflows\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents = {}\n",
    "        self.workflow_history = []\n",
    "    \n",
    "    def register_agent(self, name: str, agent: OllamaStrandAgent):\n",
    "        \"\"\"Register an agent with the orchestrator\"\"\"\n",
    "        self.agents[name] = agent\n",
    "        print(f\"Registered agent: {name}\")\n",
    "    \n",
    "    def sequential_workflow(self, workflow_steps: List[Dict[str, Any]]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Execute a sequential workflow where each step depends on the previous\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        context = \"\"\n",
    "        \n",
    "        for i, step in enumerate(workflow_steps):\n",
    "            agent_name = step['agent']\n",
    "            prompt = step['prompt']\n",
    "            \n",
    "            if agent_name not in self.agents:\n",
    "                raise ValueError(f\"Agent {agent_name} not registered\")\n",
    "            \n",
    "            # Include context from previous steps\n",
    "            if context and step.get('use_context', True):\n",
    "                full_prompt = f\"Previous context:\\n{context}\\n\\nNew request:\\n{prompt}\"\n",
    "            else:\n",
    "                full_prompt = prompt\n",
    "            \n",
    "            print(f\"\\nStep {i+1}: {agent_name}\")\n",
    "            print(f\"Prompt: {prompt[:100]}...\")\n",
    "            \n",
    "            response = self.agents[agent_name].chat(full_prompt)\n",
    "            results.append(response)\n",
    "            \n",
    "            # Update context\n",
    "            context += f\"\\nStep {i+1} ({agent_name}): {response[:200]}...\"\n",
    "            \n",
    "            # Store in history\n",
    "            self.workflow_history.append({\n",
    "                'step': i+1,\n",
    "                'agent': agent_name,\n",
    "                'prompt': prompt,\n",
    "                'response': response,\n",
    "                'timestamp': time.time()\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    async def parallel_workflow(self, workflow_steps: List[Dict[str, Any]]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Execute multiple agents in parallel\n",
    "        \"\"\"\n",
    "        tasks = []\n",
    "        \n",
    "        for step in workflow_steps:\n",
    "            agent_name = step['agent']\n",
    "            prompt = step['prompt']\n",
    "            \n",
    "            if agent_name not in self.agents:\n",
    "                raise ValueError(f\"Agent {agent_name} not registered\")\n",
    "            \n",
    "            task = self.agents[agent_name].async_chat(prompt)\n",
    "            tasks.append(task)\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Store in history\n",
    "        for i, (step, result) in enumerate(zip(workflow_steps, results)):\n",
    "            self.workflow_history.append({\n",
    "                'step': i+1,\n",
    "                'agent': step['agent'],\n",
    "                'prompt': step['prompt'],\n",
    "                'response': result,\n",
    "                'timestamp': time.time(),\n",
    "                'type': 'parallel'\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def consensus_workflow(self, prompt: str, agent_names: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get responses from multiple agents and analyze consensus\n",
    "        \"\"\"\n",
    "        responses = {}\n",
    "        \n",
    "        for agent_name in agent_names:\n",
    "            if agent_name not in self.agents:\n",
    "                continue\n",
    "            \n",
    "            response = self.agents[agent_name].chat(prompt)\n",
    "            responses[agent_name] = response\n",
    "        \n",
    "        # Analyze consensus (simplified)\n",
    "        consensus_analysis = {\n",
    "            'prompt': prompt,\n",
    "            'responses': responses,\n",
    "            'agent_count': len(responses),\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        \n",
    "        return consensus_analysis\n",
    "\n",
    "# Create orchestrator and register agents\n",
    "orchestrator = AgentOrchestrator()\n",
    "\n",
    "# Create and register agents\n",
    "math_agent_instance = math_agent()\n",
    "code_agent_instance = code_agent()\n",
    "creative_agent_instance = creative_agent()\n",
    "analysis_agent_instance = analysis_agent()\n",
    "\n",
    "orchestrator.register_agent('math', math_agent_instance)\n",
    "orchestrator.register_agent('code', code_agent_instance)\n",
    "orchestrator.register_agent('creative', creative_agent_instance)\n",
    "orchestrator.register_agent('analysis', analysis_agent_instance)\n",
    "\n",
    "print(\"\\nOrchestrator setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sequential workflow for building a simple game\n",
    "game_workflow = [\n",
    "    {\n",
    "        'agent': 'creative',\n",
    "        'prompt': 'Create a concept for a simple text-based adventure game. Include theme, setting, and basic storyline.'\n",
    "    },\n",
    "    {\n",
    "        'agent': 'code',\n",
    "        'prompt': 'Based on the game concept, write Python code structure for a simple text adventure game with classes and methods.'\n",
    "    },\n",
    "    {\n",
    "        'agent': 'analysis',\n",
    "        'prompt': 'Analyze the game concept and code structure. Suggest improvements and potential features to add.'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== SEQUENTIAL WORKFLOW: GAME DEVELOPMENT ===\")\n",
    "game_results = orchestrator.sequential_workflow(game_workflow)\n",
    "\n",
    "print(\"\\n=== WORKFLOW COMPLETE ===\")\n",
    "for i, result in enumerate(game_results):\n",
    "    print(f\"\\nStep {i+1} Result:\")\n",
    "    print(result[:300] + \"...\" if len(result) > 300 else result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Parallel workflow for different perspectives\n",
    "parallel_workflow = [\n",
    "    {\n",
    "        'agent': 'creative',\n",
    "        'prompt': 'Write a creative story about AI and robotics in 2030 (100 words)'\n",
    "    },\n",
    "    {\n",
    "        'agent': 'analysis',\n",
    "        'prompt': 'Provide a data-driven analysis of AI and robotics trends for 2030'\n",
    "    },\n",
    "    {\n",
    "        'agent': 'code',\n",
    "        'prompt': 'Describe the technical architecture for AI systems in 2030'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n=== PARALLEL WORKFLOW: AI IN 2030 ===\")\n",
    "parallel_results = await orchestrator.parallel_workflow(parallel_workflow)\n",
    "\n",
    "print(\"\\n=== PARALLEL RESULTS ===\")\n",
    "for i, result in enumerate(parallel_results):\n",
    "    agent_name = parallel_workflow[i]['agent']\n",
    "    print(f\"\\n{agent_name.upper()} PERSPECTIVE:\")\n",
    "    print(result[:400] + \"...\" if len(result) > 400 else result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9eb2f5",
   "metadata": {},
   "source": [
    "## 2. Memory and Context Management\n",
    "\n",
    "Let's implement context-aware agents with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e76bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualAgent:\n",
    "    \"\"\"\n",
    "    Agent wrapper that maintains conversation context and memory\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_agent: OllamaStrandAgent, max_context_length: int = 4000):\n",
    "        self.base_agent = base_agent\n",
    "        self.conversation_history = []\n",
    "        self.max_context_length = max_context_length\n",
    "        self.context_summary = \"\"\n",
    "    \n",
    "    def chat_with_context(self, message: str) -> str:\n",
    "        \"\"\"\n",
    "        Chat with the agent while maintaining conversation context\n",
    "        \"\"\"\n",
    "        # Build context from conversation history\n",
    "        context = self._build_context()\n",
    "        \n",
    "        # Create full prompt with context\n",
    "        if context:\n",
    "            full_prompt = f\"Previous conversation context:\\n{context}\\n\\nCurrent message:\\n{message}\"\n",
    "        else:\n",
    "            full_prompt = message\n",
    "        \n",
    "        # Get response from base agent\n",
    "        response = self.base_agent.chat(full_prompt)\n",
    "        \n",
    "        # Store in conversation history\n",
    "        self.conversation_history.append({\n",
    "            'user': message,\n",
    "            'assistant': response,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        \n",
    "        # Manage context length\n",
    "        self._manage_context_length()\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _build_context(self) -> str:\n",
    "        \"\"\"\n",
    "        Build context string from conversation history\n",
    "        \"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"\"\n",
    "        \n",
    "        context_parts = []\n",
    "        if self.context_summary:\n",
    "            context_parts.append(f\"Summary: {self.context_summary}\")\n",
    "        \n",
    "        # Add recent conversations\n",
    "        for entry in self.conversation_history[-3:]:  # Last 3 exchanges\n",
    "            context_parts.append(f\"User: {entry['user']}\")\n",
    "            context_parts.append(f\"Assistant: {entry['assistant'][:200]}...\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def _manage_context_length(self):\n",
    "        \"\"\"\n",
    "        Manage context length by summarizing old conversations\n",
    "        \"\"\"\n",
    "        if len(self.conversation_history) > 10:\n",
    "            # Summarize older conversations\n",
    "            old_conversations = self.conversation_history[:-5]\n",
    "            summary_text = \"\"\n",
    "            \n",
    "            for conv in old_conversations:\n",
    "                summary_text += f\"User asked about: {conv['user'][:100]}\\n\"\n",
    "                summary_text += f\"Assistant discussed: {conv['assistant'][:100]}\\n\"\n",
    "            \n",
    "            # Create summary\n",
    "            summary_prompt = f\"Summarize this conversation in 2-3 sentences:\\n{summary_text}\"\n",
    "            self.context_summary = self.base_agent.chat(summary_prompt)\n",
    "            \n",
    "            # Keep only recent conversations\n",
    "            self.conversation_history = self.conversation_history[-5:]\n",
    "    \n",
    "    def get_conversation_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get statistics about the conversation\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'total_exchanges': len(self.conversation_history),\n",
    "            'context_summary_length': len(self.context_summary) if self.context_summary else 0,\n",
    "            'first_interaction': self.conversation_history[0]['timestamp'] if self.conversation_history else None,\n",
    "            'last_interaction': self.conversation_history[-1]['timestamp'] if self.conversation_history else None\n",
    "        }\n",
    "    \n",
    "    def clear_context(self):\n",
    "        \"\"\"\n",
    "        Clear conversation context\n",
    "        \"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.context_summary = \"\"\n",
    "        print(\"Context cleared\")\n",
    "\n",
    "# Create contextual agents\n",
    "contextual_math = ContextualAgent(math_agent())\n",
    "contextual_creative = ContextualAgent(creative_agent())\n",
    "\n",
    "print(\"Contextual agents created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50248476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contextual conversation\n",
    "print(\"=== CONTEXTUAL CONVERSATION TEST ===\")\n",
    "\n",
    "# Start a math conversation\n",
    "print(\"\\n1. First math question:\")\n",
    "response1 = contextual_math.chat_with_context(\"I have a rectangle with width 5 and height 8. What's the area?\")\n",
    "print(f\"Response: {response1}\")\n",
    "\n",
    "print(\"\\n2. Follow-up question (using context):\")\n",
    "response2 = contextual_math.chat_with_context(\"What about the perimeter of the same rectangle?\")\n",
    "print(f\"Response: {response2}\")\n",
    "\n",
    "print(\"\\n3. Another follow-up:\")\n",
    "response3 = contextual_math.chat_with_context(\"If I scale this rectangle by a factor of 2, what would be the new area?\")\n",
    "print(f\"Response: {response3}\")\n",
    "\n",
    "# Check conversation stats\n",
    "stats = contextual_math.get_conversation_stats()\n",
    "print(f\"\\nConversation stats: {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942b0af",
   "metadata": {},
   "source": [
    "## 3. Error Handling and Resilience\n",
    "\n",
    "Let's implement robust error handling for agent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52284671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResilientAgent:\n",
    "    \"\"\"\n",
    "    Agent wrapper with error handling and retry logic\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_agent: OllamaStrandAgent, max_retries: int = 3, timeout: int = 30):\n",
    "        self.base_agent = base_agent\n",
    "        self.max_retries = max_retries\n",
    "        self.timeout = timeout\n",
    "        self.error_log = []\n",
    "    \n",
    "    def safe_chat(self, message: str, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Chat with retry logic and error handling\n",
    "        \"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Attempt to get response\n",
    "                response = self.base_agent.chat(message, **kwargs)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Check for timeout\n",
    "                if end_time - start_time > self.timeout:\n",
    "                    raise TimeoutError(f\"Response took {end_time - start_time:.2f}s, exceeding {self.timeout}s timeout\")\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'response': response,\n",
    "                    'attempt': attempt + 1,\n",
    "                    'duration': end_time - start_time\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_info = {\n",
    "                    'attempt': attempt + 1,\n",
    "                    'error': str(e),\n",
    "                    'error_type': type(e).__name__,\n",
    "                    'timestamp': time.time(),\n",
    "                    'message': message[:100] + \"...\" if len(message) > 100 else message\n",
    "                }\n",
    "                self.error_log.append(error_info)\n",
    "                \n",
    "                print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                \n",
    "                if attempt < self.max_retries - 1:\n",
    "                    wait_time = 2 ** attempt  # Exponential backoff\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    return {\n",
    "                        'success': False,\n",
    "                        'error': str(e),\n",
    "                        'attempts': self.max_retries,\n",
    "                        'error_log': self.error_log[-self.max_retries:]\n",
    "                    }\n",
    "    \n",
    "    def get_health_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get agent health and error statistics\n",
    "        \"\"\"\n",
    "        total_errors = len(self.error_log)\n",
    "        recent_errors = len([e for e in self.error_log if time.time() - e['timestamp'] < 3600])  # Last hour\n",
    "        \n",
    "        return {\n",
    "            'agent_name': self.base_agent.name,\n",
    "            'total_errors': total_errors,\n",
    "            'recent_errors_1h': recent_errors,\n",
    "            'error_rate': recent_errors / max(1, total_errors) if total_errors > 0 else 0,\n",
    "            'last_error': self.error_log[-1] if self.error_log else None\n",
    "        }\n",
    "    \n",
    "    def clear_error_log(self):\n",
    "        \"\"\"\n",
    "        Clear the error log\n",
    "        \"\"\"\n",
    "        self.error_log = []\n",
    "        print(\"Error log cleared\")\n",
    "\n",
    "# Create resilient agents\n",
    "resilient_math = ResilientAgent(math_agent(), max_retries=2, timeout=15)\n",
    "resilient_code = ResilientAgent(code_agent(), max_retries=2, timeout=20)\n",
    "\n",
    "print(\"Resilient agents created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de864a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resilient agent\n",
    "print(\"=== RESILIENT AGENT TEST ===\")\n",
    "\n",
    "# Normal operation\n",
    "result1 = resilient_math.safe_chat(\"Calculate 15 * 24 + 36\")\n",
    "print(f\"\\nResult 1: {result1}\")\n",
    "\n",
    "# Test with a complex question\n",
    "result2 = resilient_code.safe_chat(\"Write a Python function to implement binary search\")\n",
    "print(f\"\\nResult 2: {result2['success']}, Duration: {result2.get('duration', 'N/A')}s\")\n",
    "\n",
    "# Check health status\n",
    "health_math = resilient_math.get_health_status()\n",
    "health_code = resilient_code.get_health_status()\n",
    "\n",
    "print(f\"\\nMath agent health: {health_math}\")\n",
    "print(f\"Code agent health: {health_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413df9bd",
   "metadata": {},
   "source": [
    "## 4. Performance Monitoring and Optimization\n",
    "\n",
    "Let's implement performance monitoring for our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMonitor:\n",
    "    \"\"\"\n",
    "    Monitor and analyze agent performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "        self.agent_stats = {}\n",
    "    \n",
    "    def log_interaction(self, agent_name: str, prompt: str, response: str, duration: float, success: bool = True):\n",
    "        \"\"\"\n",
    "        Log an agent interaction for performance analysis\n",
    "        \"\"\"\n",
    "        metric = {\n",
    "            'agent_name': agent_name,\n",
    "            'prompt_length': len(prompt),\n",
    "            'response_length': len(response),\n",
    "            'duration': duration,\n",
    "            'success': success,\n",
    "            'timestamp': time.time(),\n",
    "            'tokens_per_second': len(response.split()) / max(duration, 0.1)\n",
    "        }\n",
    "        \n",
    "        self.metrics.append(metric)\n",
    "        \n",
    "        # Update agent stats\n",
    "        if agent_name not in self.agent_stats:\n",
    "            self.agent_stats[agent_name] = {\n",
    "                'total_requests': 0,\n",
    "                'successful_requests': 0,\n",
    "                'total_duration': 0,\n",
    "                'total_tokens': 0\n",
    "            }\n",
    "        \n",
    "        stats = self.agent_stats[agent_name]\n",
    "        stats['total_requests'] += 1\n",
    "        if success:\n",
    "            stats['successful_requests'] += 1\n",
    "        stats['total_duration'] += duration\n",
    "        stats['total_tokens'] += len(response.split())\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get performance summary across all agents\n",
    "        \"\"\"\n",
    "        if not self.metrics:\n",
    "            return {'error': 'No metrics recorded'}\n",
    "        \n",
    "        total_requests = len(self.metrics)\n",
    "        successful_requests = sum(1 for m in self.metrics if m['success'])\n",
    "        average_duration = sum(m['duration'] for m in self.metrics) / total_requests\n",
    "        average_tokens_per_sec = sum(m['tokens_per_second'] for m in self.metrics) / total_requests\n",
    "        \n",
    "        return {\n",
    "            'total_requests': total_requests,\n",
    "            'success_rate': successful_requests / total_requests,\n",
    "            'average_duration': round(average_duration, 2),\n",
    "            'average_tokens_per_second': round(average_tokens_per_sec, 2),\n",
    "            'agents_active': len(self.agent_stats)\n",
    "        }\n",
    "    \n",
    "    def get_agent_performance(self, agent_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get performance metrics for a specific agent\n",
    "        \"\"\"\n",
    "        if agent_name not in self.agent_stats:\n",
    "            return {'error': f'No data for agent {agent_name}'}\n",
    "        \n",
    "        stats = self.agent_stats[agent_name]\n",
    "        \n",
    "        return {\n",
    "            'agent_name': agent_name,\n",
    "            'total_requests': stats['total_requests'],\n",
    "            'success_rate': stats['successful_requests'] / max(stats['total_requests'], 1),\n",
    "            'average_duration': round(stats['total_duration'] / max(stats['total_requests'], 1), 2),\n",
    "            'average_tokens_per_request': round(stats['total_tokens'] / max(stats['successful_requests'], 1), 2),\n",
    "            'requests_per_minute': stats['total_requests'] / max((time.time() - self.metrics[0]['timestamp']) / 60, 1) if self.metrics else 0\n",
    "        }\n",
    "    \n",
    "    def get_slowest_requests(self, top_n: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get the slowest requests for optimization analysis\n",
    "        \"\"\"\n",
    "        sorted_metrics = sorted(self.metrics, key=lambda x: x['duration'], reverse=True)\n",
    "        return sorted_metrics[:top_n]\n",
    "\n",
    "# Create performance monitor\n",
    "perf_monitor = PerformanceMonitor()\n",
    "\n",
    "class MonitoredAgent:\n",
    "    \"\"\"\n",
    "    Agent wrapper that logs performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_agent: OllamaStrandAgent, monitor: PerformanceMonitor):\n",
    "        self.base_agent = base_agent\n",
    "        self.monitor = monitor\n",
    "    \n",
    "    def chat(self, message: str, **kwargs) -> str:\n",
    "        start_time = time.time()\n",
    "        success = True\n",
    "        response = \"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.base_agent.chat(message, **kwargs)\n",
    "        except Exception as e:\n",
    "            success = False\n",
    "            response = f\"Error: {str(e)}\"\n",
    "        finally:\n",
    "            duration = time.time() - start_time\n",
    "            self.monitor.log_interaction(\n",
    "                self.base_agent.name,\n",
    "                message,\n",
    "                response,\n",
    "                duration,\n",
    "                success\n",
    "            )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        # Delegate other attributes to the base agent\n",
    "        return getattr(self.base_agent, name)\n",
    "\n",
    "# Create monitored agents\n",
    "monitored_math = MonitoredAgent(math_agent(), perf_monitor)\n",
    "monitored_creative = MonitoredAgent(creative_agent(), perf_monitor)\n",
    "monitored_code = MonitoredAgent(code_agent(), perf_monitor)\n",
    "\n",
    "print(\"Performance monitoring setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb36c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance monitoring\n",
    "print(\"=== PERFORMANCE MONITORING TEST ===\")\n",
    "\n",
    "# Run various requests to generate performance data\n",
    "test_requests = [\n",
    "    (monitored_math, \"Calculate the factorial of 10\"),\n",
    "    (monitored_creative, \"Write a haiku about programming\"),\n",
    "    (monitored_code, \"Write a function to reverse a string\"),\n",
    "    (monitored_math, \"What is the derivative of x^3 + 2x^2 - 5x + 1?\"),\n",
    "    (monitored_creative, \"Create a short story about a robot learning to paint\"),\n",
    "    (monitored_code, \"Implement a binary tree in Python\")\n",
    "]\n",
    "\n",
    "print(\"Running test requests...\")\n",
    "for i, (agent, prompt) in enumerate(test_requests):\n",
    "    print(f\"\\nRequest {i+1}: {agent.name} - {prompt[:50]}...\")\n",
    "    response = agent.chat(prompt)\n",
    "    print(f\"Response length: {len(response)} characters\")\n",
    "\n",
    "print(\"\\n=== PERFORMANCE ANALYSIS ===\")\n",
    "\n",
    "# Overall performance summary\n",
    "summary = perf_monitor.get_performance_summary()\n",
    "print(f\"\\nOverall Performance:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Individual agent performance\n",
    "for agent_name in ['MathAgent', 'CreativeAgent', 'CodeAgent']:\n",
    "    agent_perf = perf_monitor.get_agent_performance(agent_name)\n",
    "    if 'error' not in agent_perf:\n",
    "        print(f\"\\n{agent_name} Performance:\")\n",
    "        for key, value in agent_perf.items():\n",
    "            if key != 'agent_name':\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "# Slowest requests\n",
    "slowest = perf_monitor.get_slowest_requests(3)\n",
    "print(f\"\\nSlowest Requests:\")\n",
    "for i, request in enumerate(slowest):\n",
    "    print(f\"  {i+1}. {request['agent_name']}: {request['duration']:.2f}s ({request['prompt_length']} chars prompt)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51328c0",
   "metadata": {},
   "source": [
    "## 5. Advanced Agent Composition\n",
    "\n",
    "Let's create complex agent compositions and workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPipeline:\n",
    "    \"\"\"\n",
    "    Create complex pipelines of agent operations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.stages = []\n",
    "        self.results = []\n",
    "    \n",
    "    def add_stage(self, agent: OllamaStrandAgent, transform_fn=None, condition_fn=None):\n",
    "        \"\"\"\n",
    "        Add a stage to the pipeline\n",
    "        \n",
    "        Args:\n",
    "            agent: The agent to use in this stage\n",
    "            transform_fn: Function to transform input before sending to agent\n",
    "            condition_fn: Function to determine if this stage should run\n",
    "        \"\"\"\n",
    "        stage = {\n",
    "            'agent': agent,\n",
    "            'transform_fn': transform_fn,\n",
    "            'condition_fn': condition_fn\n",
    "        }\n",
    "        self.stages.append(stage)\n",
    "        return self\n",
    "    \n",
    "    def run(self, initial_input: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run the pipeline with initial input\n",
    "        \"\"\"\n",
    "        current_input = initial_input\n",
    "        self.results = []\n",
    "        \n",
    "        for i, stage in enumerate(self.stages):\n",
    "            # Check condition if provided\n",
    "            if stage['condition_fn'] and not stage['condition_fn'](current_input, self.results):\n",
    "                print(f\"Stage {i+1} skipped due to condition\")\n",
    "                continue\n",
    "            \n",
    "            # Transform input if provided\n",
    "            stage_input = current_input\n",
    "            if stage['transform_fn']:\n",
    "                stage_input = stage['transform_fn'](current_input, self.results)\n",
    "            \n",
    "            print(f\"\\nStage {i+1}: {stage['agent'].name}\")\n",
    "            print(f\"Input: {stage_input[:100]}...\")\n",
    "            \n",
    "            # Run the agent\n",
    "            try:\n",
    "                stage_output = stage['agent'].chat(stage_input)\n",
    "                \n",
    "                stage_result = {\n",
    "                    'stage': i+1,\n",
    "                    'agent': stage['agent'].name,\n",
    "                    'input': stage_input,\n",
    "                    'output': stage_output,\n",
    "                    'success': True,\n",
    "                    'timestamp': time.time()\n",
    "                }\n",
    "                \n",
    "                self.results.append(stage_result)\n",
    "                current_input = stage_output  # Output becomes input for next stage\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_result = {\n",
    "                    'stage': i+1,\n",
    "                    'agent': stage['agent'].name,\n",
    "                    'input': stage_input,\n",
    "                    'error': str(e),\n",
    "                    'success': False,\n",
    "                    'timestamp': time.time()\n",
    "                }\n",
    "                self.results.append(error_result)\n",
    "                print(f\"Stage {i+1} failed: {e}\")\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            'pipeline_name': self.name,\n",
    "            'initial_input': initial_input,\n",
    "            'final_output': current_input,\n",
    "            'stages_completed': len([r for r in self.results if r['success']]),\n",
    "            'total_stages': len(self.stages),\n",
    "            'results': self.results\n",
    "        }\n",
    "\n",
    "# Example: Research and Content Creation Pipeline\n",
    "content_pipeline = AgentPipeline(\"Content Creation Pipeline\")\n",
    "\n",
    "# Stage 1: Research (Analysis Agent)\n",
    "def research_transform(input_text, results):\n",
    "    return f\"Research this topic and provide key insights: {input_text}\"\n",
    "\n",
    "content_pipeline.add_stage(\n",
    "    analysis_agent(),\n",
    "    transform_fn=research_transform\n",
    ")\n",
    "\n",
    "# Stage 2: Structure (Code Agent for logical structure)\n",
    "def structure_transform(input_text, results):\n",
    "    return f\"Based on this research, create a logical outline for an article: {input_text[:500]}\"\n",
    "\n",
    "content_pipeline.add_stage(\n",
    "    code_agent(),\n",
    "    transform_fn=structure_transform\n",
    ")\n",
    "\n",
    "# Stage 3: Write Content (Creative Agent)\n",
    "def content_transform(input_text, results):\n",
    "    research = results[0]['output'][:300] if results else \"\"\n",
    "    return f\"Write an engaging article using this outline and research:\\nOutline: {input_text}\\nResearch: {research}\"\n",
    "\n",
    "content_pipeline.add_stage(\n",
    "    creative_agent(),\n",
    "    transform_fn=content_transform\n",
    ")\n",
    "\n",
    "print(\"Content creation pipeline configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2173585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the content creation pipeline\n",
    "print(\"=== RUNNING CONTENT CREATION PIPELINE ===\")\n",
    "\n",
    "topic = \"The impact of artificial intelligence on remote work productivity\"\n",
    "pipeline_result = content_pipeline.run(topic)\n",
    "\n",
    "print(f\"\\n=== PIPELINE RESULTS ===\")\n",
    "print(f\"Pipeline: {pipeline_result['pipeline_name']}\")\n",
    "print(f\"Topic: {pipeline_result['initial_input']}\")\n",
    "print(f\"Stages completed: {pipeline_result['stages_completed']}/{pipeline_result['total_stages']}\")\n",
    "\n",
    "for result in pipeline_result['results']:\n",
    "    if result['success']:\n",
    "        print(f\"\\nStage {result['stage']} ({result['agent']}):\")\n",
    "        print(f\"Output: {result['output'][:300]}...\")\n",
    "    else:\n",
    "        print(f\"\\nStage {result['stage']} FAILED: {result['error']}\")\n",
    "\n",
    "print(f\"\\nFinal Article Length: {len(pipeline_result['final_output'])} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65423e45",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this advanced patterns notebook, we've explored:\n",
    "\n",
    "1. **Agent Orchestration**: Sequential, parallel, and consensus workflows\n",
    "2. **Context Management**: Memory-aware agents that maintain conversation history\n",
    "3. **Error Handling**: Resilient agents with retry logic and error recovery\n",
    "4. **Performance Monitoring**: Metrics collection and analysis for optimization\n",
    "5. **Agent Composition**: Complex pipelines and multi-stage workflows\n",
    "\n",
    "These patterns enable you to build sophisticated, production-ready AI agent systems that can handle complex tasks, maintain context, recover from errors, and provide insights into their performance.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement custom orchestration patterns for your specific use cases\n",
    "- Add persistent storage for conversation context and metrics\n",
    "- Integrate with monitoring systems for production deployments\n",
    "- Explore distributed agent architectures\n",
    "- Implement agent learning and adaptation mechanisms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
