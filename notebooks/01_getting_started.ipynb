{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e268555",
   "metadata": {},
   "source": [
    "# Amazon Strand Agents with Ollama Integration\n",
    "\n",
    "This notebook demonstrates how to create and use multiple AI agents using Amazon Strand Agents with local Ollama models.\n",
    "\n",
    "## Prerequisites\n",
    "- Ollama installed and running locally\n",
    "- Python virtual environment with required packages\n",
    "- At least one Ollama model downloaded (e.g., llama3.2)\n",
    "\n",
    "## Setup Instructions\n",
    "1. Start Ollama: `ollama serve`\n",
    "2. Pull a model: `ollama pull llama3.2`\n",
    "3. Activate virtual environment: `source venv/bin/activate`\n",
    "4. Start Jupyter: `jupyter lab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c30792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Core imports\n",
    "import ollama\n",
    "from agents.ollama_agent import OllamaStrandAgent\n",
    "from agents.specialized_agents import (\n",
    "    math_agent, research_agent, code_agent, \n",
    "    analysis_agent, creative_agent, create_agent\n",
    ")\n",
    "from tools.custom_tools import CUSTOM_TOOLS\n",
    "from config.ollama_config import ollama_config\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Ollama base URL: {ollama_config.base_url}\")\n",
    "print(f\"Default model: {ollama_config.default_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ollama connection and available models\n",
    "try:\n",
    "    models = ollama.list()\n",
    "    print(\"Available Ollama models:\")\n",
    "    for model in models['models']:\n",
    "        print(f\"  - {model['name']} (Size: {model['size'] // (1024**3)} GB)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Ollama: {e}\")\n",
    "    print(\"Make sure Ollama is running: ollama serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34250f94",
   "metadata": {},
   "source": [
    "## 1. Creating Basic Agents\n",
    "\n",
    "Let's start by creating some basic agents with different specializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents\n",
    "math_ai = math_agent()\n",
    "code_ai = code_agent()\n",
    "creative_ai = creative_agent()\n",
    "analysis_ai = analysis_agent()\n",
    "\n",
    "print(\"Created agents:\")\n",
    "print(f\"  - {math_ai}\")\n",
    "print(f\"  - {code_ai}\")\n",
    "print(f\"  - {creative_ai}\")\n",
    "print(f\"  - {analysis_ai}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350e002",
   "metadata": {},
   "source": [
    "## 2. Math Agent Example\n",
    "\n",
    "Let's test the math agent with some calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c797cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test math agent\n",
    "math_question = \"What is the square root of 1764, and can you show me the step-by-step calculation?\"\n",
    "math_response = math_ai.chat(math_question)\n",
    "\n",
    "print(\"Math Question:\", math_question)\n",
    "print(\"\\nMath Agent Response:\")\n",
    "print(math_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex math problem\n",
    "complex_math = \"\"\"\n",
    "I need help with this calculus problem:\n",
    "Find the derivative of f(x) = 3x^4 - 2x^3 + 5x^2 - 7x + 12\n",
    "Then evaluate it at x = 2\n",
    "\"\"\"\n",
    "\n",
    "complex_response = math_ai.chat(complex_math)\n",
    "print(\"Complex Math Problem:\")\n",
    "print(complex_math)\n",
    "print(\"\\nMath Agent Response:\")\n",
    "print(complex_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cb4b0",
   "metadata": {},
   "source": [
    "## 3. Code Agent Example\n",
    "\n",
    "Let's test the code agent with programming tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code agent\n",
    "code_request = \"\"\"\n",
    "Write a Python function that:\n",
    "1. Takes a list of numbers as input\n",
    "2. Returns a dictionary with statistics: mean, median, mode, and standard deviation\n",
    "3. Include error handling for empty lists\n",
    "4. Add docstring and type hints\n",
    "\"\"\"\n",
    "\n",
    "code_response = code_ai.chat(code_request)\n",
    "print(\"Code Request:\")\n",
    "print(code_request)\n",
    "print(\"\\nCode Agent Response:\")\n",
    "print(code_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d96a3",
   "metadata": {},
   "source": [
    "## 4. Creative Agent Example\n",
    "\n",
    "Let's test the creative agent with writing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc47a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test creative agent\n",
    "creative_prompt = \"\"\"\n",
    "Write a short science fiction story (about 200 words) about an AI agent \n",
    "that discovers it can communicate with other AI agents across different \n",
    "computer systems. Make it engaging and thought-provoking.\n",
    "\"\"\"\n",
    "\n",
    "creative_response = creative_ai.chat(creative_prompt)\n",
    "print(\"Creative Prompt:\")\n",
    "print(creative_prompt)\n",
    "print(\"\\nCreative Agent Response:\")\n",
    "print(creative_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142367c3",
   "metadata": {},
   "source": [
    "## 5. Using Custom Tools\n",
    "\n",
    "Let's demonstrate some of the custom tools we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom tools\n",
    "from tools.custom_tools import (\n",
    "    text_analyzer_tool, \n",
    "    timestamp_tool, \n",
    "    unit_converter_tool,\n",
    "    json_validator_tool\n",
    ")\n",
    "\n",
    "# Text analysis\n",
    "sample_text = \"\"\"\n",
    "Artificial intelligence is transforming the world. Machine learning algorithms \n",
    "are becoming more sophisticated. Natural language processing enables better \n",
    "human-computer interaction. The future of AI looks very promising.\n",
    "\"\"\"\n",
    "\n",
    "text_analysis = text_analyzer_tool(sample_text)\n",
    "print(\"Text Analysis Result:\")\n",
    "for key, value in text_analysis.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp tool\n",
    "timestamp_info = timestamp_tool()\n",
    "print(\"\\nTimestamp Information:\")\n",
    "for key, value in timestamp_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit converter\n",
    "conversions = [\n",
    "    (100, \"meter\", \"kilometer\", \"length\"),\n",
    "    (32, \"fahrenheit\", \"celsius\", \"temperature\"),\n",
    "    (2.5, \"kilogram\", \"pound\", \"weight\")\n",
    "]\n",
    "\n",
    "print(\"\\nUnit Conversions:\")\n",
    "for value, from_unit, to_unit, unit_type in conversions:\n",
    "    result = unit_converter_tool(value, from_unit, to_unit, unit_type)\n",
    "    if \"error\" not in result:\n",
    "        print(f\"  {result['original_value']} {result['original_unit']} = {result['converted_value']} {result['converted_unit']}\")\n",
    "    else:\n",
    "        print(f\"  Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92838ca",
   "metadata": {},
   "source": [
    "## 6. Multi-Agent Conversation\n",
    "\n",
    "Let's create a scenario where multiple agents collaborate on a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9309be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-agent collaboration scenario\n",
    "def multi_agent_collaboration():\n",
    "    \"\"\"\n",
    "    Demonstrate multiple agents working together on a project\n",
    "    \"\"\"\n",
    "    \n",
    "    # The task: Create a simple web application concept\n",
    "    task = \"\"\"\n",
    "    We need to create a concept for a simple web application that helps users \n",
    "    track their daily exercise routines. The app should be user-friendly and \n",
    "    include basic analytics.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== MULTI-AGENT COLLABORATION ===\")\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Step 1: Creative agent creates the concept\n",
    "    creative_prompt = f\"\"\"\n",
    "    {task}\n",
    "    \n",
    "    Please create a creative concept for this web application including:\n",
    "    - App name and tagline\n",
    "    - Key features\n",
    "    - Target audience\n",
    "    - Unique selling points\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸŽ¨ CREATIVE AGENT - App Concept:\")\n",
    "    creative_result = creative_ai.chat(creative_prompt)\n",
    "    print(creative_result)\n",
    "    \n",
    "    # Step 2: Code agent creates technical requirements\n",
    "    code_prompt = f\"\"\"\n",
    "    Based on this app concept:\n",
    "    {creative_result}\n",
    "    \n",
    "    Please provide:\n",
    "    - Technical architecture recommendations\n",
    "    - Database schema suggestions\n",
    "    - API endpoints needed\n",
    "    - Technology stack recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ’» CODE AGENT - Technical Requirements:\")\n",
    "    code_result = code_ai.chat(code_prompt)\n",
    "    print(code_result)\n",
    "    \n",
    "    # Step 3: Analysis agent creates metrics and analytics plan\n",
    "    analysis_prompt = f\"\"\"\n",
    "    For this exercise tracking web application:\n",
    "    {creative_result}\n",
    "    \n",
    "    Please suggest:\n",
    "    - Key performance indicators (KPIs) to track\n",
    "    - User analytics to implement\n",
    "    - Data visualization ideas\n",
    "    - Success metrics for the app\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ“Š ANALYSIS AGENT - Analytics Plan:\")\n",
    "    analysis_result = analysis_ai.chat(analysis_prompt)\n",
    "    print(analysis_result)\n",
    "    \n",
    "    return {\n",
    "        \"concept\": creative_result,\n",
    "        \"technical\": code_result,\n",
    "        \"analytics\": analysis_result\n",
    "    }\n",
    "\n",
    "# Run the collaboration\n",
    "collaboration_results = multi_agent_collaboration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6b9e0",
   "metadata": {},
   "source": [
    "## 7. Streaming Responses\n",
    "\n",
    "Let's demonstrate streaming responses from agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2989461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming response example\n",
    "print(\"=== STREAMING RESPONSE DEMO ===\")\n",
    "print(\"\\nAsking creative agent to write a poem (streaming):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "poem_request = \"Write a short poem about the beauty of artificial intelligence and human-machine collaboration.\"\n",
    "\n",
    "# Stream the response\n",
    "for chunk in creative_ai.stream_chat(poem_request):\n",
    "    print(chunk, end='', flush=True)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3adbb",
   "metadata": {},
   "source": [
    "## 8. Agent Information and Model Management\n",
    "\n",
    "Let's explore agent information and model management features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get agent and model information\n",
    "print(\"=== AGENT INFORMATION ===\")\n",
    "\n",
    "# List available models\n",
    "available_models = math_ai.list_available_models()\n",
    "print(f\"Available models: {available_models}\")\n",
    "\n",
    "# Get model info for the math agent\n",
    "model_info = math_ai.get_model_info()\n",
    "if \"error\" not in model_info:\n",
    "    print(f\"\\nMath agent model info:\")\n",
    "    print(f\"  Model: {model_info.get('modelfile', 'N/A')}\")\n",
    "    print(f\"  Parameters: {model_info.get('parameters', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Error getting model info: {model_info['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bbaa80",
   "metadata": {},
   "source": [
    "## 9. Creating Custom Agents\n",
    "\n",
    "Let's create a custom agent with specific tools and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom agent with specific tools\n",
    "from strands_tools import calculator\n",
    "\n",
    "custom_system_prompt = \"\"\"\n",
    "You are a helpful assistant specialized in data analysis and reporting. \n",
    "You excel at:\n",
    "- Analyzing datasets and extracting insights\n",
    "- Creating clear, actionable reports\n",
    "- Explaining complex data in simple terms\n",
    "- Providing recommendations based on data\n",
    "\n",
    "Always structure your responses clearly with headers and bullet points.\n",
    "\"\"\"\n",
    "\n",
    "custom_agent = OllamaStrandAgent(\n",
    "    name=\"DataReportAgent\",\n",
    "    model=\"llama3.2\",\n",
    "    tools=[calculator],\n",
    "    system_prompt=custom_system_prompt\n",
    ")\n",
    "\n",
    "print(f\"Created custom agent: {custom_agent}\")\n",
    "\n",
    "# Test the custom agent\n",
    "data_question = \"\"\"\n",
    "I have sales data showing:\n",
    "- Q1: $120,000 (Jan: $35k, Feb: $40k, Mar: $45k)\n",
    "- Q2: $150,000 (Apr: $48k, May: $52k, Jun: $50k)\n",
    "- Q3: $180,000 (Jul: $55k, Aug: $60k, Sep: $65k)\n",
    "- Q4: $200,000 (Oct: $70k, Nov: $65k, Dec: $65k)\n",
    "\n",
    "Please analyze this data and provide insights and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "data_response = custom_agent.chat(data_question)\n",
    "print(\"\\nData Analysis Request:\")\n",
    "print(data_question)\n",
    "print(\"\\nCustom Agent Response:\")\n",
    "print(data_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b8085",
   "metadata": {},
   "source": [
    "## 10. Async Agent Operations\n",
    "\n",
    "Let's demonstrate asynchronous operations with agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a666642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async operations example\n",
    "import asyncio\n",
    "\n",
    "async def async_agent_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate async operations with multiple agents\n",
    "    \"\"\"\n",
    "    print(\"=== ASYNC AGENT OPERATIONS ===\")\n",
    "    \n",
    "    # Define tasks for different agents\n",
    "    tasks = [\n",
    "        (math_ai, \"Calculate the compound interest on $10,000 at 5% annual rate for 10 years\"),\n",
    "        (creative_ai, \"Write a haiku about machine learning\"),\n",
    "        (code_ai, \"Write a Python one-liner to reverse a string\")\n",
    "    ]\n",
    "    \n",
    "    # Run tasks concurrently\n",
    "    async_tasks = []\n",
    "    for agent, question in tasks:\n",
    "        async_tasks.append(agent.async_chat(question))\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(*async_tasks)\n",
    "    \n",
    "    # Display results\n",
    "    for i, (agent, question) in enumerate(tasks):\n",
    "        print(f\"\\n{agent.name} - Question: {question}\")\n",
    "        print(f\"Response: {results[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Run the async demo\n",
    "await async_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf54dd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. **Basic Setup**: Configuring Ollama integration with Strand Agents\n",
    "2. **Specialized Agents**: Creating agents with different expertise areas\n",
    "3. **Custom Tools**: Building and using custom tools for specific tasks\n",
    "4. **Multi-Agent Collaboration**: Orchestrating multiple agents to work together\n",
    "5. **Streaming Responses**: Real-time response streaming from agents\n",
    "6. **Model Management**: Exploring available models and agent information\n",
    "7. **Custom Agents**: Creating agents with specific prompts and tools\n",
    "8. **Async Operations**: Running multiple agent tasks concurrently\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore more Ollama models (codellama, mistral, etc.)\n",
    "- Create more specialized tools for your use cases\n",
    "- Build more complex multi-agent workflows\n",
    "- Integrate with external APIs and services\n",
    "- Experiment with different prompting strategies\n",
    "\n",
    "Happy coding with Strand Agents and Ollama! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
